* General description
  This application is used to populate the historical database with monitoring information collected for each region by the FIWARE monitoring system.

  In the application there is a collector which runs periodically (daily) as a batch job. This collector is able to perform various queries towards the Monasca master node using the monascaAPI and retrieve historical and aggregated information in order to populate responses of the following APIs, described [[http://docs.federationmonitoring.apiary.io/#][here]]: Services4Region, Region, Host, VM, Host2Host, Service4Host, Service4VM, NE.

  From the above API, the following entities can be summarized: sanity_check, service, region, host and VMs. In the first phase entities are filtered only by region and should have the following attributes/measurements:
  1) sanity_check
     - avg_Uptime: sanityOK / sanityTOT
     - timestamp
     - aggrType
  2) service
     - avg_Uptime
     - timestamp
     - serviceType (cinder_api, cinder_scheduler, nova_api ...)
     - aggrType

  Each measurements collected from the previous day must be aggregated monthly, daily and hourly and then inserted into a new MySql database, respecting the same structure present in the current historical database.

* Deployment and run
  The application is intended to run periodically every day. It is suggested to run it after midnight since the default behavior is to collect from the MonascaAPI the historical information of the day before and store them into the historical MySQL db.

** Deployment & run for development
    1) Create a virtualenv
       #+BEGIN_EXAMPLE
       mkvirtualenv monitoringHisto
       #+END_EXAMPLE
    2) Install the dependencies
       #+BEGIN_EXAMPLE
       pip install -r requirements.txt
       #+END_EXAMPLE
    3) Create an executable in the virtualenv
       #+BEGIN_EXAMPLE
       python setup.py develop
       #+END_EXAMPLE
    4) Run the executable (also from outside the virtualenv)
       #+BEGIN_EXAMPLE
       $VIRTUAL_ENV/bin/monitoringHisto
       #+END_EXAMPLE

** Deployment for production
   1) Create a dist package
      #+BEGIN_EXAMPLE
      python setup.py sdist      
      #+END_EXAMPLE

** Cronjob setup
   Depending on how the package has been deployed the cronjob configuration change. Insert the following into a cronjob to start the script at 00:15 every day:
   1) Development /(executable available in the venv)/
      #+BEGIN_EXAMPLE
      15 0 * * * PATH_OF_THE_VENV/bin/monitoringHisto -c PATH/config.ini
      #+END_EXAMPLE
   2) Production /(executable available from the package)/
      #+BEGIN_EXAMPLE
      15 0 * * * PATH_OF_THE_PACKAGE/bin/monitoringHisto -c PATH/config.ini
      #+END_EXAMPLE
* Additional features
** Specify custom period
   It is possible to specify a custom period on which to elaborate data. 

   This can be done using =--start-day, -s= and =--end-day, -e= as arguments to the command line.
** Specify custom region
   It is possible to specify a custom single region on which to elaborate data. 

   This can be done using =--region-id, -r= as argument to the command line.
** Exclude specific regions
   It is possible to *exclude* specific regions from the configuration file. This is particular useful in the transition phase when a region must be enabled for real-time monitoring but for some reasons it can not yet be enabled for historical data import.

   The config section looks like this:
   #+BEGIN_EXAMPLE
   [regionexclude]
   regions = []
   # eg: regions = ["region1", "region2"]
   #+END_EXAMPLE
   
** Include specific services
   It is possible to *include* specific services from the configuration file. This is particular useful to speed-up the time of import and process data.

   The config section looks like this:

   #+BEGIN_EXAMPLE   
   [servicesinclude]
   services = []
   # eg: services = ["compute", "networking", "block-storage", "image-service"]
   #+END_EXAMPLE
